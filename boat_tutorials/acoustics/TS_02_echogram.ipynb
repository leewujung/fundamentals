{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ffe7da-2e0d-4121-9f97-20cf1aa2f1e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(acoustics-scattering_echogram)=\n",
    "# Echogram\n",
    "\n",
    "How do echoes \"look\" like? Just like spectrogram that provides a visual representation of sound, we can color-code the receiving echoes across \"pings\" (or sonar transmissions) to assemble **echogram** as a visual representation of echoes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37655367-cfcf-4105-ba0f-e44d08748e37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In a [monostatic](acoustics-scattering_monostatic_bistatic) configuration when the propagation environment is simple (i.e., constant sound speed), we can use the delay from the time of sound transmission to the time an echo is received ($\\Delta t$) to map out the distance between the transducer and the scatterer source ($\\Delta d$)\n",
    "\n",
    "$$\\Delta t = \\frac{2 \\Delta d}{c}$$\n",
    "\n",
    "where $c$ is the sound speed and the factor of 2 captures the _roundtrip_ propagation path length.\n",
    "\n",
    "For example, below is a sketch of how an echogram is assembled for a fish swimming up toward a downward-looking echosounder:\n",
    "\n",
    "```{image} ../images/TS/echogram_build.png\n",
    ":width: 600px\n",
    ":align: center\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce8bcf8-d55a-4a5f-af15-f88d8de09cc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Echogram is an interesting plot, because both the vertical and horizontal axis are in the unit of time: the vertical axis are the _global_ time of each ping, and the horizontal axis are the _local_ time measured from the start of each ping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c4f6c1-6ea4-43ae-8d52-baac8b9bf78a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Echogram examples\n",
    "\n",
    "Depending on the instrument and the measurement geometry, echograms can take many forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1ab8c-e0c4-4857-85cc-db434e049274",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Vertical-looking systems\n",
    "\n",
    "When sonar systems are aimed vertically, either downward from the sea surface or upward from the seafloor, the echograms are typically plotted as a sheet that cuts across space (when the sonar is on a moving platform) or just across time (when the sonar is fixed).\n",
    "\n",
    "For example, below is an echogram from by a ship-mounted, downward-looking fisheries echosounder, with the horizontal axis being the distance traveled across pings.\n",
    "\n",
    "```{image} ../images/TS/echogram_ship.png\n",
    ":width: 700px\n",
    ":align: center\n",
    "```\n",
    "<!-- <img src=\"../images/TS/echogram_ship.png\" alt=\"\" width=\"700\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8882d-3801-4789-9bb1-762fed03bccb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The same echosounder can be moored (fixed) on an underwater platform looking upward, producing a similar echogram with the horizontal axis being ping time.\n",
    "\n",
    "```{image} ../images/TS/echogram_mooring.png\n",
    ":width: 715px\n",
    ":align: center\n",
    "```\n",
    "<!-- <img src=\"../images/TS/echogram_mooring.png\" alt=\"\" width=\"715\"> -->\n",
    "\n",
    "In both cases, the vertical axis is range from the transducer, which can be transformed to depth once we compensate for the depth of the transducer itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaccf48-87c9-49bc-bebf-4d5b0fbb79ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::{note}\n",
    "How do we know what's in an echogram? Usually we rely on acoustic scattering models and contextual information about the environment to guide our interpretation. Learn more about these models in [](acoustics-scattering_discrete).\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c385922-add2-444c-8cc2-bd9d9008b49d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- ### Horizontal-looking systems\n",
    "\n",
    "If the sonar is aimed sideways, which is typical for systems optimized for long range observation), the echogram is usually rotated sideways to align with our intuitive understand of the space.\n",
    "\n",
    "For example, below is an echogram from a horizontal-looking sonar system aimed toward a specific direction in shallow (~20 m) water. Different from the above, the vertical axis is now ping time and the horizontal axis is range from the transducer.\n",
    "\n",
    "<mark>[ADD ECHOGRAM WITH TARGET MOVING ACROSS TIME]</mark> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3494d33-75ea-4480-b34e-2a4eb64aa4b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- If the horizontal-looking sonar system has multiple \"beams\" looking into different directions, we can generate echograms by aligning all echoes generated from the same ping across angles. For example, below are a series of such echograms centered around the sonar system in a bird's-eye view. Each echogram is a \"snapshot\" of the envronment from a single ping, showing fish emerging and spreading from artificial reef around dusk (from [this paper](https://doi.org/10.1121/1.5054013)). \n",
    "\n",
    "```{image} ../images/TS/trex_fish_frames.jpeg\n",
    ":width: 700px\n",
    ":align: center\n",
    "``` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34881060-27e9-4ab5-8553-bae4fb238bf5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- :::{tip}\n",
    "See the [](acoustics-beampattern) page to learn more about what the concept of sonar beams!\n",
    "::: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8824ce1-a84c-4fa5-9877-6ef4a759848d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
